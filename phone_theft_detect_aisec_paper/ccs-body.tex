\section{Introduction}

According to Consumer Reports, 2.1 million smartphones were stolen in the United States in 2014~\cite{deitrick:consumer}, and the Pew Research Center's Internet \& American Life Project reported in 2012 that nearly one third of mobile phone users have experienced a lost or stolen devices~\cite{boyles:pew}.
People can lock their phones to mitigate the risks of phone theft, but some find this less convenient as it requires unlocking their phone every time they want to use their phone.
About 40\% of smartphone users do not lock their phones, which allows thieves to gain access to the victims' personal information~\cite{egelman:lock}.

In this paper, we develop a method to automatically detect pickpocket and grab-and-run smartphone theft. To be more specific, we train a binary classifier to recognize the movements that are specific to theft and use it monitor accelerometer data in the background.
When theft is detected, it can signal the device to lock the phone and optionally notify the owner. Thus, our theft detector offers another layer of protection against smartphone theft.
Because our detector is completely automatic, it is convenient for users.

There are multiple ways that a phone might be stolen.
We focus specifically on grab-and-run theft, where the thief snatches the phone out of the user's hand and runs away, and pickpocket theft, where the thief steals the phone from the user's pocket or bag and runs away.
This creates an abrupt and unusual movement pattern, which we show can be detected from analysis of accelerometer sensor data.
We do not attempt to detect other forms of theft, such as where the phone is left unattended and the thief walks off with it, or where the phone is lost or left behind somewhere.
Consequently, our scheme cannot offer comprehensive protection against all forms of theft, but we hope that it will be useful nonetheless.

We measure the effectiveness of our scheme by gathering two datasets.
First, we simulated three types of phone theft: grab-and-run while the victim is standing still, grab-and-run while the victim is walking at a constant speed, and pick-pocket theft.
We collect accelerometer sensor readings during the simulated thefts; these serve as known positives.
Second, we conducted a field study where we collected 3 weeks of sensor readings from the phones of 53 participants during their everyday life.
No phone was stolen during the field study, so these serve as known negatives.
We use this to train a classifier and then evaluate its detection rate and false positive rate.
Our best classifier produces 1 false alarm per week on average while detecting 100\% of simulated thefts.


Our contributions are:
\begin{enumerate}
  \item We conduct a user study and collect a large dataset of smartphone sensor data while devices are being used in real world.
  \item We devise features and methods to detect theft, and we show that it can detect thefts with few false positives.
\end{enumerate}

\input{cfp}
% \input{cfp}
% \input{cfp}

\section{Conclusions}

In this work, we demonstrate that accelerometer data is enough to detect some common forms of smartphone theft, such as pickpocket and grab-and-run, without sacrificing user experience. 
It is remarkable that machine learning is so effective and can detect 100\% of thefts.
We suspect that this is because the kinds of theft we consider here involve a rapid jerking motion followed by the thief running away, which induces a unique pattern in the accelerometer sensor readings.

We envision that a smartphone could run our classifier continuously and automatically lock the phone whenever a suspected theft event is detected.
We expect that the inconvenience of unlocking your phone one extra time per week would be tolerable, and might not even be noticed by users.
If combined with other heuristics to reduce the false positive rate further (e.g., the phone is not unlocked within a short period after the suspected theft; the phone moves to some new location it has never been before), it might be possible to notify the owner or take other measures as well when a theft is detected.

We expect that our solution would have negligible impact on battery life and phone performance.
Modern phones support batched accelerometer sensing, where the accelerometer hardware buffers sensor readings so the application CPU only has to wake up to read sensor data when the buffer is full.
As a result, it is possible to record accelerometer sensor values at high sampling rates with negligible power draw.
Moreover, thanks to the pre-filtering (the~$40 m/s^2$ threshold),
we only need to apply the classifier on a tiny fraction of time windows (only about 10 times per hour),
so the impact on battery life should be negligible.

The primary limitation of our work is that we work with simulated thefts.
It is difficult to obtain accelerometer data on actual theft occurring in the wild, but perhaps a practical deployment could obtain such data.

It may be possible to improve our results further by using other sensors on the smartphone, such as the step counter.
The biggest open question is whether our methods can be extended to a more diverse set of theft scenarios; we hope that our work will inspire others to investigate the direction further.


% \appendix

% \section{Location}

% Note that in the new ACM style, the Appendices come before the References.

% \input{cfp}

\begin{acks}
% TODO: For the submission, don't include acknowledgments since they would most likely deanonymize you.
\begin{comment}
\textcolor{red}{Comment out for double blind review}. 

The authors would like to thank Prakash P. Bhasker and Micah J. Sheller for proivding with the Android sensor monitoring software, Jennider Chen from the Good Research for her assistance on conducting the user study, and Irwin Reyes, David Fifield \textcolor{red}{Who else gives feedback to draft} for giving feedback to our paper drafts. 
This research was conducted at The Intel Science and Technology Center for Secure Computing (http://scrub.cs.berkeley.edu/) at UC Berkeley. 
The work is supported by \textcolor{red}{What Grants and Funds}. 
\end{comment}
\end{acks}
