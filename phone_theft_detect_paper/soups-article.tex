% This is "sig-alternate.tex" V1.8 June 2007 Modified for SOUPS 2014
% This file should be compiled with V2.3 of "sig-alternate.cls" June 2007
%
% This example file demonstrates the use of the 'sig-alternate.cls'
% V2.3 LaTeX2e document class file. It is for those submitting
% articles to ACM Conference Proceedings WHO DO NOT WISH TO
% STRICTLY ADHERE TO THE SIGS (PUBS-BOARD-ENDORSED) STYLE.
% The 'sig-alternate.cls' file will produce a similar-looking,
% albeit, 'tighter' paper resulting in, invariably, fewer pages.
%
% ----------------------------------------------------------------------------------------------------------------
% This .tex file (and associated .cls V2.3) produces:
%       1) The Permission Statement
%       2) The Conference (location) Info information
%       3) The Copyright Line with ACM data
%       4) NO page numbers
%
% as against the acm_proc_article-sp.cls file which
% DOES NOT produce 1) thru' 3) above.
%
% Using 'sig-alternate.cls' you have control, however, from within
% the source .tex file, over both the CopyrightYear
% (defaulted to 200X) and the ACM Copyright Data
% (defaulted to X-XXXXX-XX-X/XX/XX).
% e.g.
% \CopyrightYear{2007} will cause 2007 to appear in the copyright line.
% \crdata{0-12345-67-8/90/12} will cause 0-12345-67-8/90/12 to appear in the copyright line.
%
% ---------------------------------------------------------------------------------------------------------------
% This .tex source is an example which *does* use
% the .bib file (from which the .bbl file % is produced).
% REMEMBER HOWEVER: After having produced the .bbl file,
% and prior to final submission, you *NEED* to 'insert'
% your .bbl file into your source .tex file so as to provide
% ONE 'self-contained' source file.
%
% ================= IF YOU HAVE QUESTIONS =======================
% Questions regarding the SIGS styles, SIGS policies and
% procedures, Conferences etc. should be sent to
% Adrienne Griscti (griscti@acm.org)
%
% Technical questions _only_ to
% Gerald Murray (murray@acm.org)
% ===============================================================
%
% For tracking purposes - this is V1.8 - June 2007

% --- Start page size ---
%Please use the following format  
\documentclass{soups} 
\pdfpagewidth=8.5truein 
\pdfpageheight=11truein 
% --- End page size ---


\usepackage{graphicx}
\usepackage{times}
\usepackage{url}
\usepackage{color}
\usepackage{booktabs}
\usepackage{float}

\renewcommand{\topfraction}{0.99} % be more aggressive about text around floats
\renewcommand{\floatpagefraction}{0.99}
\pagestyle{plain} % page numbers



\begin{document}
%
% --- Author Metadata here ---
\conferenceinfo{Conference}{year, month dates, city, state.}
\CopyrightYear{2017} % Allows default copyright year (200X) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Detecting Phone Theft Using Machine Learning}
% \titlenote{(Produces the permission block, and copyright information). For use with SIG-ALTERNATE.CLS. Supported by ACM.}}
% \subtitle{Subtitle (optional)%
% \titlenote{A full version of this paper is available as
% \textit{Author's Guide to Preparing ACM SIG Proceedings Using
% \LaTeX$2_\epsilon$\ and BibTeX} at
% \texttt{www.acm.org/sigs/publications/sigguide-v2.2sp}}}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

% \numberofauthors{3} %  in this sample file, there are a *total*
% of EIGHT authors. SIX appear on the 'first-page' (for formatting
% reasons) and the remaining two appear in the \additionalauthors section.
%
% \author{
% You can go ahead and credit any number of authors here,
% e.g. one 'row of three' or two rows (consisting of one row of three
% and a second row of one, two or three).
%
% The command \alignauthor (no curly braces needed) should
% precede each author name, affiliation/snail-mail address and
% e-mail address. Additionally, tag each line of
% affiliation/address with \affaddr, and tag the
% e-mail address with \email.
%
% 1st. author
% \alignauthor
% Xinyu Liu \\
%        \affaddr{UC Berkeley} \\
%        \email{xinyuliu@berkeley.edu}
% % 2nd. author
% \alignauthor
% David Wagner \\
%        \affaddr{UC Berkeley} \\
%        \email{daw@cs.berkeley.edu}
% % 3rd. author
% \alignauthor 
% Serge Egelman \\
%        \affaddr{UC Berkeley, ICSI} \\
%        \email{egelman@cs.berkeley.edu}
% \and  % use '\and' if you need 'another row' of author names
% % 4th. author
% \alignauthor Lawrence P. Leipuner\\
%        \affaddr{Brookhaven Laboratories}\\
%        \affaddr{Brookhaven National Lab}\\
%        \affaddr{P.O. Box 5000}\\
%        \email{lleipuner@researchlabs.org}
% % 5th. author
% \alignauthor Sean Fogarty\\
%        \affaddr{NASA Ames Research Center}\\
%        \affaddr{Moffett Field}\\
%        \affaddr{California 94035}\\
%        \email{fogartys@amesres.org}
% % 6th. author
% \alignauthor Charles Palmer\\
%        \affaddr{Palmer Research Laboratories}\\
%        \affaddr{8600 Datapoint Drive}\\
%        \affaddr{San Antonio, Texas 78229}\\
%        \email{cpalmer@prl.com}
% }
% There's nothing stopping you putting the seventh, eighth, etc.
% author on the opening page (as the 'third row') but we ask,
% for aesthetic reasons that you place these 'additional authors'
% in the \additional authors block, viz.
% \additionalauthors{Additional authors: John Smith (The Th{\o}rv{\"a}ld Group,
% email: {\texttt{jsmith@affiliation.org}}) and Julius P.~Kumquat
% (The Kumquat Consortium, email: {\texttt{jpkumquat@consortium.net}}).}
% \date{30 July 1999}
% Just remember to make sure that the TOTAL number of authors
% is the number that will appear on the first page PLUS the
% number that will appear in the \additionalauthors section.

\maketitle
\begin{abstract}
Millions of smartphones are stolen in the United States every year, putting victims' personal information at risk since many users often do not lock their phones. 
To protect individuals' smartphones and the private data stored on them, we develop a system that automatically detects pickpocket and grab-and-run theft, where a thief grabs the phone from a victim's hand then runs away. 
Our system applies machine learning to smartphone accelerometer data. Based on a field study and simulated theft scenarios, we are able to detect all thefts at a cost of 1 false alarm per week.
\end{abstract}




\section{Introduction}
According to Consumer Reports, 2.1 million smartphones were stolen in the United States in 2014 \cite{deitrick:consumer}, and the Pew Research Center's Internet \& American Life Project reported in 2012 that nearly one third of mobile phone users have experienced a lost or stolen devices \cite{boyles:pew}.
People can lock their phones to mitigate the risks of phone theft, but this is less convenient as it requires unlocking their phone every time they want to use their phone.
Consequently, about 40\% of smartphone users do not lock their phones, which allows thieves to gain access to the victims' personal information \cite{egelman:lock}.

In this paper, we develop a method to automatically detect detect pickpocket and grab-and-run smartphone theft. To be more specific, we train a binary classifier to recognize the movements that are specific to theft and use it monitor accelerometer data in the background.
When theft is detected, it can signal the device to lock the phone and notify the owner. Thus, our theft detector offers another layer of protection against smartphone theft.
Because our detector is completely automatic, it is convenient for users.

There are multiple ways that a phone might be stolen.
We focus specifically on grab-and-run theft, where the thief snatches the phone out of the user's hand and runs away, and pickpocket theft, where the thief steals the phone from the user's pocket or bag and runs away.
This creates an abrupt and unusual movement pattern, which we show can be detected from analysis of accelerometer sensor data.
We do not attempt to detect other forms of theft, such as where the phone is left unattended and the thief walks off with it, or where the phone is lost or left behind somewhere.
Consequently, our scheme cannot offer comprehensive protection against all forms of theft, but we hope that it will be useful nonetheless.

We measure the effectiveness of our scheme by gathering two datasets.
First, we simulated three types of phone theft: grab-and-run while the victim is standing still, grab-and-run while the victim is walking at a constant speed, and pick-pocket theft.
We collect accelerometer sensor readings during the simulated thefts; these serve as known positives.
Second, we conducted a field study where we collected 3 weeks of sensor readings from the phones of 53 participants during their everyday life.
No phone was stolen during the field study, so these serve as known negatives.
We use this to train a classifier and then evaluate its detection rate and false positive rate.
Our best classifier produces 1 false alarm per week while detecting 100\% of simulated thefts.


Our contributions are:
\begin{enumerate}
  \item We conduct a user study and collect a large dataset of smartphone sensor data while devices are being used in real world.
  \item We devise features and methods to detect theft, and we show that it can detect thefts with few false positives.
\end{enumerate}




\section{Related Work}

Many researchers have studied using smartphone sensors for continuous user authentication.
The benefit of continuous user authentication is that it happens unobtrusively, without requiring any action from users.
Continuous authentication could serve as a mitigation for theft: if the phone can detect rapidly enough that it is no longer being used by the rightful owner, it could lock itself to prevent the thief from accessing sensitive data on the phone.

One approach is to use smartphone accelerometer data for gait recognition.
These systems often extract some features from the sensor data and then apply machine learning.
Derawi et al.  achieved an equal error rate of 20\% \cite{derawi:gait}.
``Equal error rate'' is a measure of accuracy where the system is tuned so the false accept rate and false reject rates are equal, and then that error rate is reported.
Primo et al. show that accelerometer-based gait authentication is somewhat dependent on the position in which the phone is held, which is a challenge for deploying gait authentication outside of a laboratory environment \cite{primo:context}. 
They showed how to infer the position of the phone (in the person's hand vs in their pocket) with 85\% accuracy, and they showed how to use this information to increase the accuracy of user authentication to 70--80\%.
They do not report performance as equal error rate.
Juefei-Xu et al. show that the pace at which people walk also affects the sensor readings, and it is possible to improve accuracy by first identifying the pace at which the user is walking, then using a model tailored towards that pace \cite{xu:pace}.
Their system achieved an equal error rate of 4--8\% (depending on the pace); or a false reject rate of 0.5--5\% at a false accept rate of 0.1\%.
Kwapisz et al. generalized gait authentication to cover not just walking but also jogging and ascending and descending stairs \cite{kwapisz:biometrics} and
achieved false reject rates of 10-15\% at a false accept rate of about 5\%.

It is not clear whether gait recognition is sufficient on its own for deployable user authentication.
One limitation is that it can only attempt to authenticate the user while the user is walking; when the user is still, it cannot infer user identity.
Another limitation is that the error rate is still fairly high: if the classifier is run continuously, once per second, even a false reject rate as low as 0.5\% will cause hundreds or thousands of false rejections per week.
Thus, gait recognition might need to be combined with other methods to yield a deployable defense against theft.

We learned from the methods they used to process sensor data and extract features.
The accelerometer sensor provides raw data in the form of $X,Y,Z$ accelerations; it is useful to also compute the magnitude $M=\sqrt{X^2+Y^2+Z^2}$ of the acceleration, as that is independent of the direction of the acceleration.
Prior papers use several methods for cleaning the raw accelerometer data, including interpolation and re-sampling to deal with irregularly sampled data and a weighted moving average filter to mitigate sensor noise.
These schemes typically divide the resulting time series into windows, each window containing about a second of sensor data.
For instance, Primo et al. use overlapping windows, with each window containing 100 samples and having an overlap of 50 samples with the next window; Derawi et a. and Juefei-Xu et al. use non-overlapping windows about 1 second in width.
Derawi. et al. and Juefei-Xu et al. use the sensor readings as the features, while Primo et al. and Kwapisz et al. compute hand-crafted features from the readings, where each feature records a summary statistic on the sensor readings in the window (e.g., mean, minimum, maximum, standard deviation, number of zero crossings, etc.).

Feng et al. investigated using the unique way the user picks up their phone as a biometric for user authentication \cite{feng:pickup}. 
They achieve equal error rate of 6--7\%.
They use the smartphone accelerometer, gyroscope, and magnetometer; in our work, we avoid the gyroscope sensor, as its power consumption is significantly higher than the accelerometer.

The most closely related work is by Chang et al., who use the way
that each person takes their phone out of their bag or pocket as a 
form of biometric authentication \cite{cheng:theft}.
They use accelerometer and gyroscope data to detect when the user picks
up their phone, and then they apply dynamic time warping and boosting to
determine whether the pickup motion matches known templates from the
owner of the phone.
Their system achieves 10\% false positive rate and 5.5\% false negative rate.
One limitation is that the 10\% false positive rate is fairly high;
considering that users may pick up their phone dozens of times each day,
this could lead to many false alarms.

The prior work focuses on authenticating the user.
In contrast, we take a different approach: we attempt to detect the
specific motion pattern that occurs during a grab-and-run or pickpocket theft.
The benefit of biometric authentication is that it provides a comprehensive
way to detect theft, regardless of the way the phone was stolen; however,
as summarized above, the false positive rates of existing schemes
are fairly high.
Our scheme is limited to detecting a particular type of theft, but achieves
far lower false positive rates.
Our classifier is also user-independent and does not require obtaining
training data from each user; we use the same classifier for all users.


\section{Methodology}

\subsection{Data Collection}

\subsubsection{Software and Hardware}
We use an Android application to record data from the smartphone's 3-axis accelerometer.
It collects sensor data, encrypts it, and stores in the cloud.
We acquire sensor data at the highest sampling rate supported by the phone using SENSOR\_DELAY\_FASTEST \cite{android:doc}. 
On most devices including the one we use for the simulated theft experiment, the sampling rate is 100 Hz. 

\subsubsection{Simulated Theft Experiment}
We simulated three types of smartphone theft scenarios with one researcher acting as a smartphone user and another one playing the role of a thief. 
The three theft scenarios are as follows:
\begin{enumerate}
\item The user stands still and holds the phone with one hand as she is using the device, for instance reading a text; the thief approaches from behind, grabs the phone with both hands and runs away in the forward direction. 
\item The user holds the phone in front of her with one hand while walking at a constant speed; the thief approaches from behind, grabs the phone with both hands and runs away in the forward direction. 
\item The third scenario simulates pick-pocket thefts. The user places the phone in the back pocket of their pants and stands still; the thief approaches from behind, steals the phone from user's pocket and runs away in the forward direction.
\end{enumerate}
We collect 20 instances of each scenario, for a total of 60 trials. 
Data collection was split across two sessions, each consisting of 10 trials per scenario, with different researchers acting as the victim and thief in these two sessions. 
We ran the experiment on flat ground at an open space, so the experiment is not interrupted. 
We also made sure that the thief runs at least 40 feet after gaining possession of the victim's phone.
We used a Nexus 5X smartphone with Android version 7.1.1 for data collection in our simulated theft experiment. 
It uses a InvenSense MPU6515 embedded accelerometer.
Figure~\ref{fig:simtheft} plots one example of accelerometer readings from a single simulated theft.


\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{pos_acc_separated.png}
\caption{The X, Y, Z and magnitude of acceleration, respectively, from one simulated theft instance.}
\label{fig:simtheft}
\end{figure}




\subsubsection{Field Study}
We performed a field study to gather data from ordinary smartphone users
during their everyday life.
% We obtained approval from the University of California, Berkeley IRB (Institutional Review Board) for this study. 
We obtained approval from our university IRB (Institutional Review Board) for this study. 
The study was conducted in the Bay Area of the United States from September to December 2016.
None of the participant experienced a phone theft during the study interval,
so we were able to use the accelerometer data collected from user study as negative samples for our machine learning algorithms (i.e., instances of non-theft activity).

We first posted a recruitment advertisement on the Craigslist under the SF Bay Area `jobs et cetera' category in September 2016. 
We only recruited participants who used an Android smartphone with version 5.0 and above.
After obtaining their consent, we installed our application on their phone and collected data for a three-week period.
We contacted participants weekly to make sure their phones were functioning correctly and troubleshoot any data collection issues.
Each participant was paid \$150 for their participation.

The study was divided across 3 rounds; each round lasted 3 consecutive weeks. 
A total of 55 participants were recruited, and
53 out of the 55 subjects completed the study. 
In the first round, 2 of the 18 participants did not complete the study.
Detailed demographic information about the participants of this user study is listed in Table~\ref{tbl:demographics}.
In aggregate they used 21 different smartphone models from 6 different manufacturers.
We asked them how they typically carried their phone, when it wasn't in their hand; 33 reported keeping it in their pocket, 9 in their purse, 12 in a multiple locations (e.g., pocket or purse, pocket or backpack), and 1 did not respond.
Therefore, we believe we observed a wide variety of behaviors and devices in this study.

\begin{table}[H]
\centering
\begin{tabular}{rrrrrr}
\hline
      & Male & Female & Age 20--29 & 30--39 & 40+ \\ \hline
R1    & 5    & 11     & 8         & 6     & 2   \\
R2    & 10   & 8      & 7         & 7     & 4   \\
R3    & 11   & 8      & 9         & 4     & 6   \\
Total & 26   & 27     & 24        & 17    & 12  \\ \hline
\end{tabular}
\caption{Demographic Info of the User Study}
\label{tbl:demographics}
\end{table}




\subsection{Feature Extraction}

Our theft scenarios all involve a sudden movement of the phone, which causes a large acceleration.
Therefore, as a first filtering step, we filter the data to focus on times after a large motion occurs.
In particular, our classifier is activated when the magnitude of acceleration $M$ exceeds 40 $m/s^2$.
We extract a one-second window before the activation time and a $n$-second window after the activation time, compute features on each of these windows, and use them for classification.
We vary \textit{n} from 1 to 7 to obtain the best classification parameter.
We chose a threshold of 40 $m/s^2$ as all of our simulated thefts experienced accelerations exceeding that threshold.

We first identified 16 candidate features, 8 features for each of the two windows.
In particular, we computed the minimum, maximum, mean, standard deviation, root mean square, arc length, product of arc length and standard deviation, and mean absolute value, each computed on the magnitude values ($M$) within the window.
We chose to only compute these features on the magnitude of the acceleration, and not the $X$, $Y$, and $Z$ components, because the magnitude is non-directional thus more robust to various orientation of the phone. 
We then visualized the distribution of these features for the two classes and applied feature selection techniques to choose a subset of features that yield good performance.
We removed the minimum and mean absolute value from the feature list because removing them did not affect the performance of the classifiers. 
As a result, we extract a 12-dimensional feature vector, 6 features from the before-window and 6 from the after-window, every time the detector is triggered.

Let $M_1,\dots,M_k$ denote the time series of acceleration magnitudes within the window.
The features are computed as follows:
\begin{itemize}
\item \emph{Maximum}: the maximum value of the magnitude within the window, i.e., $\max(M_1,\dots,M_k)$.
\item \emph{Mean}: the average value of magnitude in a window, i.e., $(M_1+\dots + M_k)/k$.
\item \emph{Standard deviation}: the standard deviation of magnitude values in a window.
\item \emph{Root mean square}: the rms of magnitude values in a window, i.e., $(M_1^2 + \dots + M_k^2)^{1/2}/k^{1/2}$.
\item \emph{Arc length}: the average of the absolute differences between all adjacent magnitude values in a window, i.e., $(|M_2-M_1| + |M_3-M_2| + \dots + |M_k-M_{k-1}|)/(k-1)$.
\item \emph{Product of arc length and standard deviation}: the product of the two feature values.
\end{itemize}

We obtain 60 positive instances from the 60 simulated thefts.
After applying the 40 $m/s^2$ threshold, we obtain approximately approximately 248000 negative samples from the data collected in the field study. 
We then apply boolean classification techniques to this data set.


\begin{figure}[t]
\includegraphics[width=1.0\columnwidth]{neg_acc_separated.png}
\caption{The above plots are x, y, z and magnitude of acceleration, respectively, during normal usage at an arbitrary time period.}
\end{figure}



\subsection{Machine Learning Algorithms}
We evaluate three standard machine learning algorithms: linear SVM, logistic regression and random forest, provide by the Python scikit-learn library, on their efficacy of distinguishing between theft and normal usage. 
In order to mitigate the fact that we have many more negative samples than positive ones, we tweak the class weight, a class attribute built in the scikit-learn library, to produce different ratios of negative and positive class weights used in training, for example 1 : 1, 1 : 8000, and `balanced,' which adjusts the class weights to be inversely proportional to class frequencies in the input data.



\section{Results}
We ran a 10-fold cross validation on the entire dataset describled in the Feature Selection section, which consists of 60 positive samples and approximately 248,000 negative samples. 
Among the three classifiers, logistic regression performs the best in terms of producing the lowest false negative rate and the highest true positive rate. 
Besides class weights, another parameter we finetune in training is the window size \textit{n}. 
Confusion matrices of logistic regression with class weight = {0: 1.0, 1: 200.0}, random forest with class weight = {0: 1.0, 1: 5000.0} and linear SVM with class weight = {0: 1.0, 1: 1000.0} when the window size \textit{n} = 2 second are shown below.

\begin{table}[H]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
              & Predicted Negative & Predicted Positive \\ \midrule
True Negative & 248223             & 170                \\
True Positive & 0                  & 60                 \\ \bottomrule
\end{tabular}
\caption{Confusion Matrix of Logistic Regression}
\label{my-label}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
              & Predicted Negative & Predicted Positive \\ \midrule
True Negative & 248360             & 33                 \\
True Positive & 32                 & 28                 \\ \bottomrule
\end{tabular}
\caption{Confusion Matrix of Random Forest}
\label{my-label}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
              & Predicted Negative & Predicted Positive \\ \midrule
True Negative & 246522             & 1871               \\
True Positive & 42                 & 18                 \\ \bottomrule
\end{tabular}
\caption{Confusion Matrix of Linear SVM}
\label{my-label}
\end{table}


The logistic regression classifier has a false negative rate of 0.6844\%, which means that on average users receive 1 false alarm every week, and a true positive rate of 100\%. For our purpose of smartphone theft detection, linear SVM's false negative rate is too hight.

We also compute feature rankings to find the most predictive features for each classifier. 
For logistic regression, to calculate feature scores that are invariant to scaling feature values, we adjust the coefficient of each feature in the decision function by multipling it by the standard deviation of the values of this feature across all instances in the training set. 
Then we get the adjusted coefficients as the feature importances of logistic regression as -2.73319487, 0.0129842047, 0.477534932, -0.0143829911, -1.18427357, -0.0470492037, 0.0580951517, 0.880738694, 0.666823228, \\-0.937781183, 0.273227115, -2.69540663, from which we can tell the most representative features are maximum, and arc length in the before-window and product of arc length and standard deviation in the after-window. 
For random forest, we use the built-in attribute feature importances in the scikit-learn library, which estimate the relative importance of the features by computing the expected fraction of the samples they contribute to. 
Thus the higher in the tree, the more important the feature is \cite{sklearn:rfdoc}. 
We get the feature importances of random forest as 0.04751106, 0.0080411, 0.02881483, 0.01533719, 0.02245781, 0.03309431, 0.12388036, 0.20288397, 0.16426152, 0.21908845, 0.05162059, 0.0830088.

Another way to visulize the representative features is to plot a histogram of dataset and to see which features can better seperate the positive and negative data points, as shown in Figures 1 and 2.

\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\columnwidth]{hist_features_before_win_size_1_2.png}
\end{center}
\caption{histogram of features in 1-second windows before \textit{40 $m/s^2$} thresholds.}
\end{figure}

\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\columnwidth]{hist_features_after_win_size_1_2.png}
\end{center}
\caption{histogram of features in 2-second windows after \textit{40 $m/s^2$} thresholds.}
\end{figure}

To compare the performance of random forest and logistic regression, we finetune the class weight of logistic regrssion classifier to lower its true positive rate until it is approximately the same as random forest classifier, then we compare the number of false postive instances of the two classiifier. 
As a result, at a 41.7\% true positive rate (25 true positive instances), logistic regression with class weigth = {0: 1.0, 1: 2.0} has 34 false positive instances. 
At a 46.7\% true positive rate (28 true positive instances), random forest with class weight = {0: 1.0, 1: 5000.0} has 33 false positive instances. 
Thus the performance of logistic regression is at least as good as random forest.
We also include the Receiver Operating Characteristic (ROC) curves of the logistic regression with class weight = {0: 1.0, 1: 200.0} and random forest with class weight = {0: 1.0, 1: 5000.0}. 

\begin{figure}[H]
\begin{center}
\includegraphics[width=1.0\columnwidth]{roc_curves.png}
\end{center}
\caption{ROC curves of logistic regression and random forest.}
\end{figure}



\section{Discussion}
In this work, we demonstrate that with proper feature extraction we can use accelerometer data alone to detect common smartphone theft, such as pickpocket and grab-and-run, without sacrificing user experience. 
In the future, in addition to accelerometer, we propose to utilize other intrinsic-sensor available on a smartphone, such as step count and try using techiques, such as time interpolation and filtering to preprocess raw sensor data for better performance. 
We would also like to collect more positive samples to have a more diverse theft dataset that covers more theft scenarios and test our models on a hold-out test set. 
We are interested in deploying theft detector on a smartphone and test it real time performance.




\section{Acknowledgments}
\textcolor{red}{Comment out for double blind review}. 

The authors would like to thank Prakash P. Bhasker and Micah J. Sheller for proivding with the Android sensor monitoring software, Jennider Chen from the Good Research for her assistance on conducting the user study, and Irwin Reyes \textcolor{red}{Who else gives feedback to draft} for giving feedback. 
This research was conducted at The Intel Science and Technology Center for Secure Computing (http://scrub.cs.berkeley.edu/) at UC Berkeley. 
The work is supported by \textcolor{red}{What Grants and Funds}. 




% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case
% You must have a proper ".bib" file
%  and remember to run:
% latex bibtex latex latex
% to resolve all references
%
% ACM needs 'a single self-contained file'!

\end{document}
