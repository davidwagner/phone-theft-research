\section{Approach}

\subsection{Problem}
We want to predict the state of an user's phone based on the sensor data collected on the phone. 
From our observations, the most common states of the phone would be in a user's: backpack, pocket, hand, or on a table.
Upon a cursory observation of accelerometer traces, these phone states also appeared to be distinguishable and motivated
our approach to use deep learning to classify these states.
Sample accelerometer traces for the states, measured on a Nexus 5X
smartphone are shown in Figure ~\ref{fig:accelGraph}.

\begin{center}
 \scalebox{0.375}{\input{Backpack15.pgf}}
  \scalebox{0.375}{\input{Pocket7.pgf}}
  \scalebox{0.375}{\input{Hand2.pgf}}
  \scalebox{0.375}{\input{Table6.pgf}}
  \captionof{figure}{Typical acceleration graphs for our four states for a Nexus 5X.}
  \label{fig:accelGraph}
\end{center}

%\begin{figure}[t]
%\center
%\includegraphics[scale=0.25]{won_table}
%\includegraphics[scale=0.25]{joanna_table}
%\caption{Graphs of the acceleration of the Nexus 5 and 5X while on a table (at different times).}
%\end{figure}

Our goal is to allow the classifier to predict phone states no matter what action the user may be performing.
This includes times when the phone is not physically on the user. 
Of course, this means that certain cases may be very difficult to distinguish between: a phone being in a still backpack versus on a table, for example.
In future works, we propose a potential solution to this problem. 


\subsection{Features}
For creating features, the relevant sensor data were the accelerometer readings (X, Y, Z values), number of unlocks, Number of screen touches, and number of times the screen turned on/off. For each window of 0.5s of these raw sensor readings, we generate the following features:

\begin{enumerate}
\item \textit{Total number of phone unlocks}
\item \textit{Total number of phone touches}
\item \textit{Fraction of window that phone screen was on}
\item \textit{Mean acceleration in each of X, Y, Z}
\item \textit{Std. deviation of acceleration in each of X, Y, Z}
\item \textit{Mean magnitude of acceleration in each of X, Y, Z}
\item \textit{Std. deviation of magnitude of acceleration in each of X, Y, Z}
\item \textit{If phone is flat (handcrafted feature explained below)}
\end{enumerate}

The ``If phone is flat" feature was a boolean feature derived from the raw accelerometer readings. 
The feature was 1 if equations 1,2,3 below held true, and 0 otherwise.

\begin{equation}\label{eq1}
 \text{(Mean X Accel. Magnitude)} < 1.0 
\end{equation}

\begin{equation}\label{eq2}
\text{(Mean Y Accel. Magnitude)} < 1.0
\end{equation}

\begin{equation}\label{eq1}
\hspace*{-1cm}|9.8 - \text{(Mean Z Accel. Magnitude)}| < 1.0
\end{equation}

Other sensors that we considered to be relevant with predicting phone states are batched light and step count.
However, the batched light sensor is not used because of its inability to distinguish outdoor nighttime darkness and the darkness from an enclosed backpack. 
We could not use the step count sensor because the sensor data we collected showed that this sensor was not reliable. 

\subsection{Architecture}
Our architecture consists of a standard convolutional layer followed by dense fully connected layers.


\begin{figure*}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = convnet1, width = 11.5cm}}
  \caption{The architecture of our convolutional neural net}
  \label{fig:ConvNet}
  \vspace{-0.1cm}
\end{figure*}

In the convolution section, we use the raw acceleration data, which includes the acceleration in the x, y, z directions. 
After multiple one-dimensional convolution layers, max and global pooling, and dropout layers, 
we concatenate the 16 features above in order to incorporate the features that do not involve the data from the accelerometer. 
We chose to separate the features in this way in order to take advantage of the potentially periodic behavior of a user's acceleration in certain positions (e.g. walking).
The features that use the acceleration in the X, Y, Z are separated from the other binary features because we wanted to capture the time series data of the different phone states.
The other binary features are independent of the time, so these features are added in after the acceleration features go through the convolution layers.  

After the concatenation of inputs, our model has 6 dense layers culminating in  4 outputs, which match the four classes listed previously. 
Our model is shown in figure ~\ref{fig:ConvNet}.
We have experimented with other architecture, such as separate binary linear classifiers for each phone state and separate neural net classifiers for each phone state.
However, we found out this multiclass neural net classifier works best and has the highest accuracy rates. 
