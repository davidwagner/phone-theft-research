\section{Approach}

\subsection{Problem}
We want to predict the state of an user's phone based on the sensor data collected on the phone. 
From our observations, the most common states of the phone would be in a user's: backpack, pocket, hand, or on a table.
Upon a cursory observation of accelerometer traces, these phone states also appeared to be distinguishable and motivated
our approach to use deep learning to classify these states. Sample accelerometer traces for the states, measured on a Nexus 5X
smartphone are shown in figure ~\ref{fig:accelGraph}.

\begin{center}
 \scalebox{0.375}{\input{Backpack15.pgf}}
  \scalebox{0.375}{\input{Pocket7.pgf}}
  \scalebox{0.375}{\input{Hand2.pgf}}
  \scalebox{0.375}{\input{Table6.pgf}}
  \captionof{figure}{Typical acceleration graphs for our four states for a Nexus 5X.}
  \label{fig:accelGraph}
\end{center}

%\begin{figure}[t]
%\center
%\includegraphics[scale=0.25]{won_table}
%\includegraphics[scale=0.25]{joanna_table}
%\caption{Graphs of the acceleration of the Nexus 5 and 5X while on a table (at different times).}
%\end{figure}


\subsection{Features}
For creating features, the relevant sensor data were the accelerometer readings (X, Y, Z values), number of unlocks, Number of screen touches, and number of times the screen turned on/off. For each window of 0.5s of these raw sensor readings, we generate the following features:

\begin{enumerate}
\item \textit{Total number of phone unlocks}
\item \textit{Total number of phone touches}
\item \textit{Fraction of window that phone screen was on}
\item \textit{Mean acceleration in each of X, Y, Z}
\item \textit{Std. deviation of acceleration in each of X, Y, Z}
\item \textit{Mean magnitude of acceleration in each of X, Y, Z}
\item \textit{Std. deviation of magnitude of acceleration in each of X, Y, Z}
\item \textit{If phone is flat (handcrafted feature explained below)}
\end{enumerate}

The ``If phone is flat" feature was a boolean feature derived from the raw accelerometer readings. 
The feature was 1 if equations 1,2,3 below held true, and 0 otherwise.

\begin{equation}\label{eq1}
 \text{(Mean X Accel. Magnitude)} < 1.0 
\end{equation}

\begin{equation}\label{eq2}
\text{(Mean Y Accel. Magnitude)} < 1.0
\end{equation}

\begin{equation}\label{eq1}
\hspace*{-1cm}|9.8 - \text{(Mean Z Accel. Magnitude)}| < 1.0
\end{equation}



\subsection{Architecture}
Our architecture consists of a standard convolutional layer followed by dense fully connected layers.


\begin{figure*}[!h]
  \vspace{-0.2cm}
  \centering
   {\epsfig{file = convnet1, width = 11.5cm}}
  \caption{The architecture of our convolutional neural net}
  \label{fig:ConvNet}
  \vspace{-0.1cm}
\end{figure*}

In the convolution section, we use the raw acceleration data, which includes the acceleration in the x, y, z directions. 
After multiple one-dimensional convolution layers, max and global pooling, and dropout layers, 
we concatenate the 16 features above in order to incorporate the features that do not involve the data from the accelerometer. 
We chose to separate the features in this way in order to take advantage of the potentially periodic behavior of a user's acceleration in certain positions (e.g. walking).

After the concatenation of inputs, our model has 6 dense layers culminating in  4 outputs, which match the four classes listed previously. 
Our model is shown in figure ~\ref{fig:ConvNet}.
